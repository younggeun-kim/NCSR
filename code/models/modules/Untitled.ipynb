{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8741, 1.0981], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "nn.Linear(1, 2)(torch.tensor([0.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = torch.randn([16, 20, 80, 80])\n",
    "std = torch.randn([16, 1, 1, 1])\n",
    "std_expand = std.expand(-1, -1, h, w)\n",
    "gt = torch.cat([gt, std_expand], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 21, 80, 80])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data_young/super_resolution2/SRFlow/code/')\n",
    "#import models.modules.StdConditional.StdConditionalLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "\n",
    "from models.modules import thops\n",
    "from utils.util import opt_get\n",
    "\n",
    "\n",
    "class StdConditionalLayer(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.scaleLayer = nn.Linear(1, in_channels)\n",
    "        self.shiftLayer = nn.Linear(1, in_channels)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, logdet=None, reverse=False, std=None):\n",
    "        if not reverse:\n",
    "            z = input\n",
    "            b = z.size(0)\n",
    "            # Std Conditional\n",
    "            scaleFt, shiftFt = torch.sigmoid(self.scaleLayer(std.view(-1,1))).view(b, -1, 1, 1), self.shiftLayer(std.view(-1,1)).view(b, -1, 1, 1)\n",
    "            z = z + shiftFt\n",
    "            z = z * scaleFt\n",
    "            logdet = logdet + self.get_logdet(scaleFt)\n",
    "            \n",
    "            output = z\n",
    "        else:\n",
    "            z = input\n",
    "            b = z.size(0)\n",
    "            # Std Conditional\n",
    "            scaleFt, shiftFt = torch.sigmoid(self.scaleLayer(std.view(-1,1))).view(b, -1, 1, 1), self.shiftLayer(std.view(-1,1)).view(b, -1, 1, 1)\n",
    "            z = z / scale\n",
    "            z = z - shift\n",
    "            logdet = logdet - self.get_logdet(scaleFt)\n",
    "\n",
    "            output = z\n",
    "        return output, logdet\n",
    "\n",
    "    def get_logdet(self, scale):\n",
    "        return thops.sum(torch.log(scale), dim=[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdL = StdConditionalLayer(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 12, 80, 80])\n",
      "torch.Size([16, 12, 1, 1])\n",
      "tensor([[[ -9.1392]],\n",
      "\n",
      "        [[ -8.9860]],\n",
      "\n",
      "        [[ -9.4006]],\n",
      "\n",
      "        [[-10.5550]],\n",
      "\n",
      "        [[ -9.0152]],\n",
      "\n",
      "        [[ -9.1680]],\n",
      "\n",
      "        [[ -9.2981]],\n",
      "\n",
      "        [[ -8.9835]],\n",
      "\n",
      "        [[ -8.9842]],\n",
      "\n",
      "        [[ -9.1849]],\n",
      "\n",
      "        [[ -9.0086]],\n",
      "\n",
      "        [[-10.8575]],\n",
      "\n",
      "        [[-10.6167]],\n",
      "\n",
      "        [[ -9.1143]],\n",
      "\n",
      "        [[ -9.8286]],\n",
      "\n",
      "        [[ -9.0117]]], grad_fn=<SqueezeBackward3>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-20618a529e2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstdL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-3da1a3f17427>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, logdet, reverse, std)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaleFt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaleFt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaleFt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "input = torch.ones([16, 12, 80, 80])\n",
    "std=torch.randn([16, 1, 1, 1])\n",
    "stdL(input, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class _ActNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Activation Normalization\n",
    "    Initialize the bias and scale with a given minibatch,\n",
    "    so that the output per-channel have zero mean and unit variance for that.\n",
    "    After initialization, `bias` and `logs` will be trained as parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, scale=1.):\n",
    "        super().__init__()\n",
    "        # register mean and scale\n",
    "        size = [1, num_features, 1, 1]\n",
    "        self.register_parameter(\"bias\", nn.Parameter(torch.zeros(*size)))\n",
    "        self.register_parameter(\"logs\", nn.Parameter(torch.zeros(*size)))\n",
    "        self.num_features = num_features\n",
    "        self.scale = float(scale)\n",
    "        self.inited = False\n",
    "\n",
    "    def _check_input_dim(self, input):\n",
    "        return NotImplemented\n",
    "\n",
    "    def initialize_parameters(self, input):\n",
    "        self._check_input_dim(input)\n",
    "        if not self.training:\n",
    "            return\n",
    "        if (self.bias != 0).any():\n",
    "            self.inited = True\n",
    "            return\n",
    "        assert input.device == self.bias.device, (input.device, self.bias.device)\n",
    "        with torch.no_grad():\n",
    "            bias = thops.mean(input.clone(), dim=[0, 2, 3], keepdim=True) * -1.0\n",
    "            vars = thops.mean((input.clone() + bias) ** 2, dim=[0, 2, 3], keepdim=True)\n",
    "            logs = torch.log(self.scale / (torch.sqrt(vars) + 1e-6))\n",
    "            self.bias.data.copy_(bias.data)\n",
    "            self.logs.data.copy_(logs.data)\n",
    "            self.inited = True\n",
    "\n",
    "    def _center(self, input, reverse=False, offset=None):\n",
    "        bias = self.bias\n",
    "\n",
    "        if offset is not None:\n",
    "            bias = bias + offset\n",
    "\n",
    "        if not reverse:\n",
    "            return input + bias\n",
    "        else:\n",
    "            return input - bias\n",
    "\n",
    "    def _scale(self, input, logdet=None, reverse=False, offset=None):\n",
    "        logs = self.logs\n",
    "\n",
    "        if offset is not None:\n",
    "            logs = logs + offset\n",
    "\n",
    "        if not reverse:\n",
    "            input = input * torch.exp(logs) # should have shape batchsize, n_channels, 1, 1\n",
    "            # input = input * torch.exp(logs+logs_offset)\n",
    "        else:\n",
    "            input = input * torch.exp(-logs)\n",
    "        if logdet is not None:\n",
    "            \"\"\"\n",
    "            logs is log_std of `mean of channels`\n",
    "            so we need to multiply pixels\n",
    "            \"\"\"\n",
    "            dlogdet = thops.sum(logs) * thops.pixels(input)\n",
    "            if reverse:\n",
    "                dlogdet *= -1\n",
    "            logdet = logdet + dlogdet\n",
    "        return input, logdet\n",
    "\n",
    "    def forward(self, input, logdet=None, reverse=False, offset_mask=None, logs_offset=None, bias_offset=None):\n",
    "        if not self.inited:\n",
    "            self.initialize_parameters(input)\n",
    "        self._check_input_dim(input)\n",
    "\n",
    "        if offset_mask is not None:\n",
    "            logs_offset *= offset_mask\n",
    "            bias_offset *= offset_mask\n",
    "        # no need to permute dims as old version\n",
    "        if not reverse:\n",
    "            # center and scale\n",
    "\n",
    "            # self.input = input\n",
    "            input = self._center(input, reverse, bias_offset)\n",
    "            input, logdet = self._scale(input, logdet, reverse, logs_offset)\n",
    "        else:\n",
    "            # scale and center\n",
    "            input, logdet = self._scale(input, logdet, reverse, logs_offset)\n",
    "            input = self._center(input, reverse, bias_offset)\n",
    "        return input, logdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum(tensor, dim=None, keepdim=False):\n",
    "    if dim is None:\n",
    "        # sum up all dim\n",
    "        return torch.sum(tensor)\n",
    "    else:\n",
    "        if isinstance(dim, int):\n",
    "            dim = [dim]\n",
    "        dim = sorted(dim)\n",
    "        for d in dim:\n",
    "            tensor = tensor.sum(dim=d, keepdim=True)\n",
    "        if not keepdim:\n",
    "            for i, d in enumerate(dim):\n",
    "                tensor.squeeze_(d-i)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def mean(tensor, dim=None, keepdim=False):\n",
    "    if dim is None:\n",
    "        # mean all dim\n",
    "        return torch.mean(tensor)\n",
    "    else:\n",
    "        if isinstance(dim, int):\n",
    "            dim = [dim]\n",
    "        dim = sorted(dim)\n",
    "        for d in dim:\n",
    "            tensor = tensor.mean(dim=d, keepdim=True)\n",
    "        if not keepdim:\n",
    "            for i, d in enumerate(dim):\n",
    "                tensor.squeeze_(d-i)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def split_feature(tensor, type=\"split\"):\n",
    "    \"\"\"\n",
    "    type = [\"split\", \"cross\"]\n",
    "    \"\"\"\n",
    "    C = tensor.size(1)\n",
    "    if type == \"split\":\n",
    "        return tensor[:, :C // 2, ...], tensor[:, C // 2:, ...]\n",
    "    elif type == \"cross\":\n",
    "        return tensor[:, 0::2, ...], tensor[:, 1::2, ...]\n",
    "\n",
    "\n",
    "def cat_feature(tensor_a, tensor_b):\n",
    "    return torch.cat((tensor_a, tensor_b), dim=1)\n",
    "\n",
    "\n",
    "def pixels(tensor):\n",
    "    return int(tensor.size(2) * tensor.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.ones([1, 3, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = torch.tensor([[0.4, 0.5], [0.8, 0.5]])\n",
    "vars = mean((input.clone()) ** 2, dim=[0, 2, 3], keepdim=True)\n",
    "logs = torch.log(scale / (torch.sqrt(vars) + 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9163, -0.6931],\n",
       "          [-0.2231, -0.6931]],\n",
       "\n",
       "         [[-0.9163, -0.6931],\n",
       "          [-0.2231, -0.6931]],\n",
       "\n",
       "         [[-0.9163, -0.6931],\n",
       "          [-0.2231, -0.6931]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.5772)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(logs) * pixels(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6094, -0.9163])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(torch.log(scale), dim=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9163, -0.6931],\n",
       "        [-0.2231, -0.6931]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from models.modules.FlowActNorms import ActNorm2d\n",
    "from models.modules import thops\n",
    "\n",
    "\n",
    "class Conv2d(nn.Conv2d):\n",
    "    pad_dict = {\n",
    "        \"same\": lambda kernel, stride: [((k - 1) * s + 1) // 2 for k, s in zip(kernel, stride)],\n",
    "        \"valid\": lambda kernel, stride: [0 for _ in kernel]\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_padding(padding, kernel_size, stride):\n",
    "        # make paddding\n",
    "        if isinstance(padding, str):\n",
    "            if isinstance(kernel_size, int):\n",
    "                kernel_size = [kernel_size, kernel_size]\n",
    "            if isinstance(stride, int):\n",
    "                stride = [stride, stride]\n",
    "            padding = padding.lower()\n",
    "            try:\n",
    "                padding = Conv2d.pad_dict[padding](kernel_size, stride)\n",
    "            except KeyError:\n",
    "                raise ValueError(\"{} is not supported\".format(padding))\n",
    "        return padding\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=[3, 3], stride=[1, 1],\n",
    "                 padding=\"same\", do_actnorm=True, weight_std=0.05):\n",
    "        padding = Conv2d.get_padding(padding, kernel_size, stride)\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                         padding, bias=(not do_actnorm))\n",
    "        # init weight with std\n",
    "        self.weight.data.normal_(mean=0.0, std=weight_std)\n",
    "        if not do_actnorm:\n",
    "            self.bias.data.zero_()\n",
    "        else:\n",
    "            self.actnorm = ActNorm2d(out_channels)\n",
    "        self.do_actnorm = do_actnorm\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = super().forward(input)\n",
    "        if self.do_actnorm:\n",
    "            x, _ = self.actnorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features,\n",
    "                  do_actnorm=True, weight_std=0.05):\n",
    "        super().__init__(in_features, out_features, bias=(not do_actnorm))\n",
    "        # init weight with std\n",
    "        self.weight.data.normal_(mean=0.0, std=weight_std)\n",
    "        if not do_actnorm:\n",
    "            self.bias.data.zero_()\n",
    "        else:\n",
    "            self.actnorm = ActNorm2d(out_features)\n",
    "        self.do_actnorm = do_actnorm\n",
    "\n",
    "    def forward(self, input):\n",
    "        b, c = input.size(0), input.size(1)\n",
    "        x = super().forward(input.view(b, c))  \n",
    "        b, c = x.size(0), x.size(1)\n",
    "        print(x.size())\n",
    "        if self.do_actnorm and len(x.size())==2:\n",
    "            print(x)\n",
    "            y = x.view(b, c, 1, 1)\n",
    "            x, _ = self.actnorm(y)\n",
    "        x = x.view(b, c, 1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearZeros(nn.Linear):\n",
    "    def __init__(self, in_features, out_features,\n",
    "                  do_actnorm=True, weight_std=0.05, logscale_factor=3):\n",
    "        super().__init__(in_features, out_features, bias=True)\n",
    "        # logscale_factor\n",
    "        self.logscale_factor = logscale_factor\n",
    "        self.register_parameter(\"logs\", nn.Parameter(torch.zeros(out_features)))\n",
    "        # init\n",
    "        self.weight.data.zero_()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = super().forward(input)\n",
    "        return output * torch.exp(self.logs * self.logscale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "tensor([[ 0.0329, -0.0244,  0.0493,  0.0084,  0.0406, -0.0476, -0.0140,  0.0439,\n",
      "         -0.0613, -0.1106, -0.0383,  0.0692, -0.0007, -0.0375,  0.0357, -0.0081,\n",
      "         -0.0023, -0.0241, -0.0656, -0.0419]], grad_fn=<MmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 1, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn([1,1])\n",
    "Linear(1, 20)(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearZeros(1,20)(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
